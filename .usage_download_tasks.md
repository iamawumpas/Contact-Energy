# Usage Download Implementation Tasks

**Project:** Contact Energy Usage Data Download & Caching  
**Version Roadmap:** v1.4.x ‚Üí v1.5.x ‚Üí v1.6.x ‚Üí v1.7.x ‚Üí v1.8.x ‚Üí v2.0.0  
**Current Phase:** Phase 4 (v1.7.x) - üîÑ IN PROGRESS  
**Status:** Phase 4 started (Energy Dashboard integration underway)  
**Last Updated:** 2026-01-08

---

## üéØ Project Overview

Implement usage data download from Contact Energy API with smart caching, incremental sync, and multi-format exposure (ApexCharts, Energy Dashboard).

### Goals
- Download hourly (9d), daily (35d), monthly (18m) usage data
- Cache data locally to minimize API calls
- Incremental sync: only download gaps/new data
- Expose data for ApexCharts (custom graphing) and HA Energy Dashboard
- Support paid/free usage breakdowns
- Restart-safe with metadata-driven sync logic

### Non-Goals (v1.4.x)
- User-configurable windows (deferred to v1.5+)
- Real-time usage updates (Contact Energy has 24-72h delay)
- Historical backfill beyond API limits (hourly: 1-2w, daily: 30d+, monthly: 2y)

---

## üìã Phase Breakdown

### Phase 1 (v1.4.x) - Core Download & Caching ‚úÖ
**Scope:** API integration, cache storage, incremental sync logic  
**Testing Environment:** Live Home Assistant server  
**Exit Criteria:** Data downloads correctly, cache persists across restarts, metadata drives sync decisions  
**Status:** ‚úÖ COMPLETE - v1.4.0 released

### Phase 2 (v1.5.x) - Sensor Exposure ‚úÖ
**Scope:** Create sensors that expose cached data  
**Exit Criteria:** Sensors update with usage data, attributes contain historical data  
**Status:** ‚úÖ COMPLETE - v1.5.9 released with fixed race condition

### Phase 3 (v1.6.x) - ApexCharts Integration ‚úÖ
**Scope:** Format data for ApexCharts consumption  
**Exit Criteria:** Users can graph hourly/daily/monthly with paid/free breakdown  
**Status:** ‚úÖ COMPLETE - v1.6.0 released with hourly_data and hourly_free_data attributes

### Phase 4 (v1.7.x) - Energy Dashboard Integration
**Scope:** Integrate with HA's built-in Energy dashboard  
**Exit Criteria:** Usage appears in Energy settings, graphs render correctly  
**Status:** üîÑ IN PROGRESS

### Phase 5 (v1.8.x) - Testing & Refinement
**Scope:** Edge cases, error handling, documentation  
**Exit Criteria:** All known issues resolved, wiki documentation complete

### v2.0.0 - Stable Release
**Scope:** Final testing, version bump, changelog  
**Exit Criteria:** Feature complete, production-ready

---

## üîß Phase 1 (v1.4.x) - Implementation Details

### 1.1 API Endpoint Implementation

**File:** `custom_components/contact_energy/contact_api.py`

**New Method:** `async def get_usage(contract_id, interval, from_date, to_date)`

**API Specification:**
```
POST /usage/v2/{contract_id}
Query Params:
  - ba={account_id}
  - interval={hourly|daily|monthly}
  - from={YYYY-MM-DD}
  - to={YYYY-MM-DD}

Headers:
  - x-api-key: {API_KEY}
  - session: {token}
  - authorization: {token}
  - Content-Type: application/json
```

**Response Format:**
```json
{
  "usage": [
    {
      "date": "2025-12-31T23:00:00+13:00",
      "value": 0.45,           // Total kWh
      "offpeakValue": 0.20,    // Free hours kWh
      "unchargedValue": 0.05,  // Promotional free kWh
      "dollarValue": 0.15,     // Total cost NZD
      "offpeakDollarValue": 0.0,
      "year": 2025,
      "month": 12,
      "day": 31,
      "hour": 23
    }
  ]
}
```

**Implementation Checklist:**
- [ ] Add `get_usage()` method to `ContactEnergyApi` class
- [ ] Validate `interval` parameter (hourly/daily/monthly only)
- [ ] Format dates as `YYYY-MM-DD` strings
- [ ] Handle 401 (expired token) ‚Üí trigger re-auth
- [ ] Handle 404 (invalid contract_id) ‚Üí log error
- [ ] Handle 400 (invalid date range) ‚Üí log and skip
- [ ] Parse response JSON and extract usage array
- [ ] Calculate `paid_value = value - offpeakValue - unchargedValue`
- [ ] Return structured data with timestamp, paid, free, cost fields
- [ ] Add timeout handling (10s default)
- [ ] Add logging for debugging (DEBUG level for data, WARNING for errors)

**Error Handling:**
```python
try:
    response = await session.post(url, params=params, headers=headers)
    if response.status == 401:
        _LOGGER.warning("Token expired, re-authenticating...")
        await self.authenticate()
        return await self.get_usage(contract_id, interval, from_date, to_date)
    elif response.status == 404:
        raise ContactEnergyApiError(f"Contract {contract_id} not found")
    elif response.status != 200:
        raise ContactEnergyApiError(f"API error {response.status}")
    
    data = await response.json()
    return self._parse_usage_response(data, interval)
except aiohttp.ClientError as e:
    raise ContactEnergyConnectionError(f"Failed to fetch usage: {e}")
```

---

### 1.2 Cache Storage Structure

**Directory:** `/config/custom_components/contact_energy/data/`  
**Files:** `usage_cache_{contract_id}.json`

**Cache Schema:**
```json
{
  "contract_id": "123456",
  "account_id": "789",
  "metadata": {
    "last_synced": "2025-12-31T14:30:00Z",
    "created": "2025-12-01T00:00:00Z",
    "version": "1.4.0",
    "hourly": {
      "from": "2025-12-23",
      "to": "2025-12-31",
      "record_count": 216
    },
    "daily": {
      "from": "2025-11-27",
      "to": "2025-12-31",
      "record_count": 35
    },
    "monthly": {
      "from": "2024-07-01",
      "to": "2025-12-01",
      "record_count": 18
    }
  },
  "hourly": {
    "2025-12-31T23:00:00": {
      "timestamp": "2025-12-31T23:00:00+13:00",
      "total": 0.45,
      "paid": 0.25,
      "free": 0.20,
      "cost": 0.15
    }
  },
  "daily": {
    "2025-12-31": {
      "timestamp": "2025-12-31T00:00:00+13:00",
      "total": 10.5,
      "paid": 8.2,
      "free": 2.3,
      "cost": 3.45
    }
  },
  "monthly": {
    "2025-12": {
      "timestamp": "2025-12-01T00:00:00+13:00",
      "total": 310.5,
      "paid": 248.4,
      "free": 62.1,
      "cost": 103.50
    }
  }
}
```

**Implementation Checklist:**
- [ ] Create `UsageCache` class in new file `usage_cache.py`
- [ ] Implement `load(contract_id)` ‚Üí read JSON from disk, handle missing file
- [ ] Implement `save(contract_id)` ‚Üí write JSON to disk, create directory if needed
- [ ] Implement `update_hourly(data)` ‚Üí merge new hourly records
- [ ] Implement `update_daily(data)` ‚Üí merge new daily records
- [ ] Implement `update_monthly(data)` ‚Üí merge new monthly records
- [ ] Implement `prune_hourly(window_days=9)` ‚Üí remove records older than window
- [ ] Implement `prune_daily(window_days=35)` ‚Üí remove records older than window
- [ ] Implement `prune_monthly(window_months=18)` ‚Üí remove records older than window
- [ ] Implement `get_hourly_range()` ‚Üí return (from_date, to_date)
- [ ] Implement `get_daily_range()` ‚Üí return (from_date, to_date)
- [ ] Implement `get_monthly_range()` ‚Üí return (from_date, to_date)
- [ ] Update metadata on every save
- [ ] Handle corrupted JSON gracefully (log warning, rebuild cache)
- [ ] Add file locking to prevent concurrent writes
- [ ] Ensure atomic writes (write to temp file, then rename)

**Directory Setup:**
```python
import os
from pathlib import Path

CACHE_DIR = Path(__file__).parent / "data"
CACHE_DIR.mkdir(parents=True, exist_ok=True)
```

---

### 1.3 Incremental Sync Logic

**File:** `custom_components/contact_energy/usage_coordinator.py` (new file)

**Sync Windows (Hard-coded v1.4):**
```python
USAGE_CONFIG = {
    'hourly': {
        'window_days': 9,
        'sync_interval': timedelta(hours=24),
        'max_lookback_days': 14  # API limit
    },
    'daily': {
        'window_days': 35,
        'sync_interval': timedelta(hours=24),
        'max_lookback_days': 60  # API limit
    },
    'monthly': {
        'window_months': 18,
        'sync_interval': timedelta(days=7),
        'max_lookback_months': 24  # API limit
    }
}
```

**Sync Algorithm:**
```python
async def sync_usage(self, contract_id: str) -> None:
    """Intelligently sync usage data with incremental downloads."""
    
    cache = self.load_cache(contract_id)
    today = date.today()
    
    # === HOURLY SYNC ===
    if self._should_sync('hourly', cache.metadata):
        hourly_from, hourly_to = cache.get_hourly_range()
        
        # Determine gap to download
        if hourly_to is None:
            # First sync: download full window
            start = today - timedelta(days=USAGE_CONFIG['hourly']['window_days'])
            end = today
        else:
            # Incremental: download only new days
            start = hourly_to + timedelta(days=1)
            end = today
        
        if start <= end:
            _LOGGER.debug(f"Syncing hourly from {start} to {end}")
            hourly_data = await self.api.get_usage(
                contract_id, 
                interval='hourly',
                from_date=start,
                to_date=end
            )
            cache.update_hourly(hourly_data)
            cache.prune_hourly(window_days=USAGE_CONFIG['hourly']['window_days'])
    
    # === DAILY SYNC ===
    if self._should_sync('daily', cache.metadata):
        daily_from, daily_to = cache.get_daily_range()
        
        if daily_to is None:
            start = today - timedelta(days=USAGE_CONFIG['daily']['window_days'])
            end = today
        else:
            start = daily_to + timedelta(days=1)
            end = today
        
        if start <= end:
            _LOGGER.debug(f"Syncing daily from {start} to {end}")
            daily_data = await self.api.get_usage(
                contract_id,
                interval='daily',
                from_date=start,
                to_date=end
            )
            cache.update_daily(daily_data)
            cache.prune_daily(window_days=USAGE_CONFIG['daily']['window_days'])
    
    # === MONTHLY SYNC ===
    if self._should_sync('monthly', cache.metadata):
        monthly_from, monthly_to = cache.get_monthly_range()
        
        if monthly_to is None:
            start = today - timedelta(days=USAGE_CONFIG['monthly']['window_months'] * 30)
            end = today
        else:
            start = monthly_to + timedelta(days=30)  # Approx 1 month
            end = today
        
        if start <= end:
            _LOGGER.debug(f"Syncing monthly from {start} to {end}")
            monthly_data = await self.api.get_usage(
                contract_id,
                interval='monthly',
                from_date=start,
                to_date=end
            )
            cache.update_monthly(monthly_data)
            cache.prune_monthly(window_months=USAGE_CONFIG['monthly']['window_months'])
    
    # Save updated cache
    cache.save()
    
    _LOGGER.info(f"Usage sync complete for contract {contract_id}")
```

**Metadata Checks:**
```python
def _should_sync(self, interval: str, metadata: dict) -> bool:
    """Determine if sync is needed based on last sync time."""
    
    last_synced = metadata.get('last_synced')
    if not last_synced:
        return True  # First sync
    
    last_sync_dt = datetime.fromisoformat(last_synced)
    now = datetime.now(timezone.utc)
    elapsed = now - last_sync_dt
    
    sync_interval = USAGE_CONFIG[interval]['sync_interval']
    
    return elapsed >= sync_interval
```

**Implementation Checklist:**
- [ ] Create `UsageCoordinator` class inheriting from `DataUpdateCoordinator`
- [ ] Implement `_should_sync()` logic with metadata checks
- [ ] Implement `sync_usage()` with all three interval types
- [ ] Handle API errors gracefully (log, skip interval, continue)
- [ ] Add retry logic for transient failures (3 retries with backoff)
- [ ] Integrate with existing `ContactEnergyCoordinator` (call from `_async_update_data`)
- [ ] Schedule sync at appropriate times (2 AM daily)
- [ ] Add debug logging for all sync decisions
- [ ] Test with missing cache (first run)
- [ ] Test with stale cache (5 days old)
- [ ] Test with fresh cache (no sync needed)

---

### 1.4 Integration with Existing Coordinator

**File:** `custom_components/contact_energy/coordinator.py`

**Current State:** Handles account data updates (balance, billing, etc.)

**Modification:**
```python
from .usage_coordinator import UsageCoordinator

class ContactEnergyCoordinator(DataUpdateCoordinator):
    def __init__(self, hass, api, contract_id):
        # ... existing init ...
        self.usage_coordinator = UsageCoordinator(hass, api, contract_id)
    
    async def _async_update_data(self):
        """Fetch account data and trigger usage sync."""
        
        # Existing account data fetch
        account_data = await self.api.get_accounts()
        
        # Trigger usage sync (non-blocking, background task)
        self.hass.async_create_task(
            self.usage_coordinator.sync_usage(self.contract_id)
        )
        
        return account_data
```

**Implementation Checklist:**
- [ ] Import `UsageCoordinator` in `coordinator.py`
- [ ] Instantiate `UsageCoordinator` in `__init__`
- [ ] Call `sync_usage()` in `_async_update_data()` as background task
- [ ] Ensure usage sync doesn't block account data updates
- [ ] Add error handling so usage failures don't break account sensors
- [ ] Test integration with existing coordinator

---

### 1.5 Testing Plan (Phase 1)

**Test Environment:** Live Home Assistant server

**Test Scenarios:**

1. **First Installation (Cold Start)**
   - [ ] Install integration v1.4.0
   - [ ] Configure with valid credentials
   - [ ] Verify cache directory created
   - [ ] Verify all three intervals download (hourly 9d, daily 35d, monthly 18m)
   - [ ] Check log for API call counts
   - [ ] Verify cache file created with correct structure
   - [ ] Check metadata: last_synced, ranges, record_counts

2. **Second Sync (Next Day)**
   - [ ] Wait 24+ hours or manually trigger coordinator refresh
   - [ ] Verify only 1 new day downloaded (hourly + daily)
   - [ ] Verify monthly not synced (7-day interval)
   - [ ] Check log: should be ~2 API calls total
   - [ ] Verify cache pruned (still 9d hourly, 35d daily)
   - [ ] Verify metadata updated

3. **Home Assistant Restart (Warm Start)**
   - [ ] Restart Home Assistant
   - [ ] Verify cache loaded from disk (no API calls)
   - [ ] Verify metadata checked (sync skipped if < 24h old)
   - [ ] Verify sensors restore with cached data
   - [ ] Check startup time (should be fast)

4. **Stale Cache (5 Days Old)**
   - [ ] Manually edit cache: set last_synced to 5 days ago
   - [ ] Restart Home Assistant
   - [ ] Verify gap fill: 5 days downloaded (hourly + daily)
   - [ ] Verify correct date range calculated
   - [ ] Verify cache up-to-date after sync

5. **Corrupted Cache**
   - [ ] Manually corrupt cache JSON (invalid syntax)
   - [ ] Restart Home Assistant
   - [ ] Verify error logged (not crash)
   - [ ] Verify cache rebuilt from scratch
   - [ ] Verify full window downloaded

6. **API Failure Scenarios**
   - [ ] Disconnect internet, trigger sync
   - [ ] Verify error logged, no crash
   - [ ] Verify retry logic (3 attempts)
   - [ ] Verify coordinator continues (account sensors still work)
   - [ ] Reconnect, verify next sync succeeds

7. **Multiple Accounts**
   - [ ] Configure 2+ accounts
   - [ ] Verify separate cache files created
   - [ ] Verify sync per-contract
   - [ ] Verify no cross-contamination

**Exit Criteria for Phase 1:**
- ‚úÖ All 7 test scenarios pass
- ‚úÖ No crashes or exceptions
- ‚úÖ API calls < 10 on first run, < 3 on subsequent runs
- ‚úÖ Cache persists across restarts
- ‚úÖ Logs are informative and debug-friendly

---

## üìä Metrics to Track

### API Efficiency
- Cold start API calls: Target < 10
- Daily update API calls: Target < 3
- Weekly average: Target < 2/day

### Performance
- Initial download time: Target < 10s
- Cache load time: Target < 500ms
- Cache save time: Target < 200ms
- Cache file size: Target < 100KB

### Reliability
- Startup success rate: Target 100%
- Sync success rate: Target > 99%
- Cache corruption rate: Target 0%

---

## üö® Known Risks & Mitigations

### Risk: Contact Energy API rate limiting
**Mitigation:** Hard-coded windows prevent excessive requests; incremental sync minimizes calls

### Risk: Large cache files on disk
**Mitigation:** Pruning logic keeps windows fixed; hourly data limited to 9 days

### Risk: Timezone issues (Pacific/Auckland)
**Mitigation:** Parse ISO timestamps with timezone; store UTC internally

### Risk: API downtime during sync
**Mitigation:** Retry logic + graceful degradation; cached data still usable

### Risk: Breaking existing functionality
**Mitigation:** Usage coordinator isolated from account coordinator; failures don't propagate

---

## üìù Code Review Checklist (Phase 1)

Before moving to Phase 2:

- [ ] All API calls have timeout handling
- [ ] All exceptions logged appropriately
- [ ] No blocking I/O in async methods
- [ ] Cache writes are atomic (no partial saves)
- [ ] Metadata always updated correctly
- [ ] Date math handles edge cases (month boundaries, leap years)
- [ ] Pruning logic doesn't delete wrong data
- [ ] Memory leaks checked (cache cleared properly)
- [ ] Type hints added to all methods
- [ ] Docstrings added to all public methods
- [ ] Debug logging comprehensive but not excessive
- [ ] No secrets or credentials logged
- [ ] Code follows existing integration style

---

## üîó Related Files

### New Files (Phase 1)
- `custom_components/contact_energy/usage_cache.py` - Cache class
- `custom_components/contact_energy/usage_coordinator.py` - Sync logic
- `custom_components/contact_energy/data/` - Cache directory

### Modified Files (Phase 1)
- `custom_components/contact_energy/contact_api.py` - Add `get_usage()` method
- `custom_components/contact_energy/coordinator.py` - Integrate usage coordinator
- `custom_components/contact_energy/manifest.json` - Version bump to 1.4.0

### Configuration Files
- `.usage_download_tasks.md` - This file
- `.Agent_Instructions.md` - Links to this file

---

## üìñ Future Phases (Brief)

### Phase 2 (v1.5.x) - Sensor Exposure
Create sensors that expose cached usage data as attributes.

**New Files:**
- `custom_components/contact_energy/usage_sensor.py`

**Sensors:**
- `sensor.contact_energy_usage_cache_{contract_id}` with attributes:
  - `hourly_data`: List of last 9 days hourly
  - `daily_data`: List of last 35 days daily
  - `monthly_data`: List of last 18 months monthly

### Phase 3 (v1.6.x) - ApexCharts Integration ‚úÖ COMPLETE

**v1.6.0 Implementation Summary:**

‚úÖ Added `hourly_data` attribute (dict keyed by ISO datetime for paid usage)  
‚úÖ Added `hourly_free_data` attribute (dict keyed by ISO datetime for free usage)  
‚úÖ Created `assets/chart_hourly_usage.yaml` with working ApexCharts card  
‚úÖ Updated `wiki/Dashboards.md` with setup guides and examples  
‚úÖ Documented template variable configuration for multi-account setup  

**Features Delivered:**
- Hourly usage visualization for last 10 days
- Separate series for free (blue #008FFB) and paid (yellow #FEB019) usage
- Gradient fill with drop shadow styling
- Responsive datetime axis with day labels
- Single-point configuration via address_icp variable
- Full documentation with step-by-step setup

### Phase 4 (v1.7.x) - Energy Dashboard Integration
Integrate with Home Assistant's Energy dashboard.

**New Sensors:**
- `sensor.contact_energy_paid_usage` (state_class: total_increasing)
- `sensor.contact_energy_free_usage` (state_class: total_increasing)

**Features:**
- Statistics database integration
- Energy configuration instructions

### Phase 5 (v1.8.x) - Testing & Documentation
Final polish before v2.0 stable release.

**Tasks:**
- Edge case testing (leap years, timezone changes, etc.)
- Performance optimization
- Wiki documentation complete
- Changelog finalized
- Release notes prepared

---

## üéØ Success Criteria for v2.0.0

- [ ] Usage data downloads reliably for all users
- [ ] Cache mechanism proven stable over 30+ days
- [ ] ApexCharts examples work out-of-box
- [ ] Energy dashboard integration functional
- [ ] API efficiency targets met (<3 calls/day steady-state)
- [ ] No critical bugs in issue tracker
- [ ] Documentation complete and clear
- [ ] At least 5 users successfully using feature (beta testing)
- [ ] Code review complete by maintainer
- [ ] Version tagged and released to HACS

---

**End of Task Document**

**Next Action:** Implement Phase 1 (`get_usage()` API method) when ready.
